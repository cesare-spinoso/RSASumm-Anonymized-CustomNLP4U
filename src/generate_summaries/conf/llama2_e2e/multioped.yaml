dataset:
  name: multioped
  path: /home/mila/c/cesare.spinoso/RSASumm/data/multioped/test.csv
  source_name: document
  question_name: question
  reference_name: summary
  document_id_name: document_id
tokenizer:
  name: meta-llama/Llama-2-7b-chat-hf
  maximum_length: 4096
model:
  name: meta-llama/Llama-2-7b-chat-hf
prompt_template: "<s>[INST] <<SYS>>\nYou are a helpful, respectful and honest assistant specializing in summarization. Provide the best summary you can while answering the question provided to you.\n<</SYS>>\nQuestion:\n{q}\nText:\n{s}\nSummary: [/INST]"
generation:
  batch_size: 1
  summary_type: e2e
  seed: 42
  generate_kwargs:
    num_beams: 5
    num_beam_groups: 5
    num_return_sequences: 5
    diversity_penalty: 1.0
    do_sample: False
    max_new_tokens: 300
    # Required to avoid Llama2 warnings
    temperature: null
    top_p: null
    early_stopping: True
    output_scores: True
    return_dict_in_generate: True
output_directory: /network/scratch/c/cesare.spinoso/rsasumm/generate_summaries/llama2_e2e/multioped
write_config_directory: /home/mila/c/cesare.spinoso/RSASumm/src/generate_summaries/config_instances/llama2_e2e
